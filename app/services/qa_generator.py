from transformers import pipeline
import pdfplumber
import re
from typing import List, Dict
import torch


class QAGenerator:
    def __init__(self):
        self.device = 0 if torch.cuda.is_available() else -1

        print("‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤...")

        self.qg_pipeline = pipeline(
            "text2text-generation",
            model="google/flan-t5-small",
            device=self.device
        )

        print("‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤...")
        self.qa_pipeline = pipeline(
            "question-answering",
            model="deepset/roberta-base-squad2",
            device=self.device
        )

        print("‚úÖ –û–±–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

    def extract_text_chunks(self, file_path: str) -> List[Dict]:
        chunks = []
        try:
            with pdfplumber.open(file_path) as pdf:
                print(f"üìÑ PDF –∏–º–µ–µ—Ç {len(pdf.pages)} —Å—Ç—Ä–∞–Ω–∏—Ü")

                for i, page in enumerate(pdf.pages):
                    text = page.extract_text()

                    if not text or not text.strip():
                        print(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i + 1}: —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω (–≤–æ–∑–º–æ–∂–Ω–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)")
                        continue

                    # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                    text = re.sub(r'\s+', ' ', text).strip()

                    if len(text) < 50:
                        print(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i + 1}: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        continue

                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    sentences = re.split(r'[.!?]+\s+', text)

                    for sent in sentences:
                        sent = sent.strip()
                        # –¢—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 20 —Å–∏–º–≤–æ–ª–æ–≤ –∏ –º–∞–∫—Å–∏–º—É–º 300
                        if 20 <= len(sent) <= 400:
                            chunks.append({
                                "text": sent,
                                "page": i + 1
                            })

                    print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i + 1}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len([c for c in chunks if c['page'] == i + 1])} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

                print(f"üìä –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return []

        return chunks

    def generate_question(self, context: str, answer_highlight: str) -> str:
        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –º–æ–¥–µ–ª–∏
            context_clean = context[:200].replace("\n", " ").strip()
            answer_clean = answer_highlight[:30].replace("\n", " ").strip()

            if not context_clean or not answer_clean:
                return f"–í–æ–ø—Ä–æ—Å –æ {answer_clean[:20]}"

            input_text = f"generate question: {context_clean} answer: {answer_clean}"

            result = self.qg_pipeline(
                input_text,
                max_new_tokens=32,
                num_beams=2
            )
            question = result[0]['generated_text'].strip()

            question = question.replace("generate question:", "").strip()

            if not question or len(question) < 5:
                question = f"–ß—Ç–æ –∑–Ω–∞—á–∏—Ç '{answer_clean}'?"

            if not question.endswith("?"):
                question += "?"

            return question
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–∞: {e}")
            return f"–í–æ–ø—Ä–æ—Å –æ '{answer_clean}'?"

    def answer_question(self, context: str, question: str) -> str:
        if not context or len(context) < 30:
            return context[:100]

        try:
            res = self.qa_pipeline(question=question, context=context[:800])
            answer = res['answer'].strip()
            return answer if answer and len(answer) > 2 else context[:100]
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ—Ç–≤–µ—Ç–∞: {e}")
            return context[:100]

    def process_pdf(self, file_path: str, max_cards: int = 10) -> List[Dict]:
        print(f"\nüîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {file_path}...")

        chunks = self.extract_text_chunks(file_path)

        if not chunks:
            print("‚ùå –ß–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã! PDF –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º.")
            return []

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")

        step = max(1, len(chunks) // max_cards)
        selected_chunks = chunks[::step][:max_cards]

        print(f"üìå –í—ã–±—Ä–∞–Ω–æ {len(selected_chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        flashcards = []
        for idx, chunk in enumerate(selected_chunks, 1):
            context = chunk['text']

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –∫–∞–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            words = re.findall(r'\b[–ê-–Ø–∞-—èA-Za-z]{3,}\b', context)
            answer_highlight = words[0] if words else context[:30]

            question = self.generate_question(context, answer_highlight)
            answer = self.answer_question(context, question)

            flashcard = {
                "id": idx,
                "question": question,
                "answer": answer,
                "context": context,
                "source": f"Page {chunk['page']}"
            }
            flashcards.append(flashcard)

            print(f"  [{idx}] Q: {question[:50]}... A: {answer[:50]}...")

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(flashcards)} –∫–∞—Ä—Ç–æ—á–µ–∫")
        return flashcards
