import re
import unicodedata
from typing import List, Dict, Optional, Tuple
import pdfplumber
import torch
from sqlalchemy.orm import Session
from app import models

class QAGenerator:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ–º:
    - –ü–æ–¥–ª–µ–∂–∞—â–µ–µ (–∫—Ç–æ)
    - –ì–ª–∞–≥–æ–ª/–ø—Ä–µ–¥–∏–∫–∞—Ç (—á—Ç–æ –¥–µ–ª–∞–ª)
    - –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ (–∫–æ–≥–æ/—á—Ç–æ)
   """

    def __init__(self, use_gpt: bool = False):
        self.device = 0 if torch.cuda.is_available() else -1
        print("‚úÖ QAGenerator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!", flush=True)

    def clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç"""
        if not text:
            return ""
        text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C' or ch in '\n\t')
        text = re.sub(r'[>~<‚Ä¢¬ª¬´‚Äû"\[\]{}()_\-‚Äì‚Äî]+', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def _clean_paragraph(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∞–±–∑–∞—Ü"""
        text = re.sub(r'\*\*', '', text)
        text = re.sub(r'^\s*[\*\-\‚Ä¢]\s*', '', text)
        text = re.sub(r'^\s*\d+[\.\s]\s*', '', text)
        text = re.sub(r'^\s*[;:]\s*', '', text)
        text = self.clean_text(text)
        return text

    def extract_meaningful_text(self, file_path: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–±–∑–∞—Ü—ã –∏–∑ PDF"""
        chunks = []

        try:
            with pdfplumber.open(file_path) as pdf:
                print(f"üìÑ PDF –∏–º–µ–µ—Ç {len(pdf.pages)} —Å—Ç—Ä–∞–Ω–∏—Ü", flush=True)

                for page_num, page in enumerate(pdf.pages):
                    raw_text = page.extract_text()
                    if not raw_text:
                        continue

                    paragraphs = raw_text.split('\n\n')

                    for para in paragraphs:
                        cleaned = self._clean_paragraph(para)

                        if len(cleaned) < 50:
                            continue

                        if any(bad in cleaned.lower()
                               for bad in ['ipynb', 'colab', 'http', '¬©', '¬Æ']):
                            continue

                        chunks.append({
                            "text": cleaned,
                            "page": page_num,
                            "word_count": len(cleaned.split())
                        })

            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(chunks)} –∞–±–∑–∞—Ü–µ–≤", flush=True)
            return chunks
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}", flush=True)
            return []

    def _split_into_sentences(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        text = text.replace('–î—Ä.', '–î—Ä_').replace('–¥—Ä.', '–¥—Ä_').replace('—Ç.–µ.', '—Ç_–µ')
        sentences = re.split(r'([.!?]+)\s+(?=[–ê-–Ø—ë–Å])', text)

        result = []
        for i in range(0, len(sentences) - 1, 2):
            if i + 1 < len(sentences):
                sentence = sentences[i] + sentences[i + 1]
                sentence = sentence.replace('–î—Ä_', '–î—Ä.').replace('–¥—Ä_', '–¥—Ä.').replace('—Ç_–µ', '—Ç.–µ')
                sentence = sentence.strip()
                if len(sentence) > 15:
                    result.append(sentence)

        if sentences and len(sentences[-1]) > 15:
            last = sentences[-1].replace('–î—Ä_', '–î—Ä.').replace('–¥—Ä_', '–¥—Ä.').replace('—Ç_–µ', '—Ç.–µ').strip()
            if last and not last.endswith(('.', '!', '?')):
                last += '.'
            if len(last) > 15:
                result.append(last)

        return result

    def _extract_parts(self, sentence: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """
        –∏–∑–≤–ª–µ–∫–∞–µ—Ç —á–∞—Å—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è:
        - subject (–ø–æ–¥–ª–µ–∂–∞—â–µ–µ)
        - verb (–≥–ª–∞–≥–æ–ª/–ø—Ä–µ–¥–∏–∫–∞—Ç)
        - obj (–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ)

        –ü—Ä–∏–º–µ—Ä—ã:
        "–ù–∞—Ü–∏—Å—Ç—ã —Å—Ç—Ä–µ–º–∏–ª–∏—Å—å –∫ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–π —ç–∫—Å–ø–∞–Ω—Å–∏–∏"
        ‚Üí subject="–ù–∞—Ü–∏—Å—Ç—ã", verb="—Å—Ç—Ä–µ–º–∏–ª–∏—Å—å", obj="—Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ–π —ç–∫—Å–ø–∞–Ω—Å–∏–∏"

        "–°–°–°–† –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª —Ä–µ—Å–ø—É–±–ª–∏–∫–∞–Ω—Å–∫–æ–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –ò—Å–ø–∞–Ω–∏–∏"
        ‚Üí subject="–°–°–°–†", verb="–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª", obj="—Ä–µ—Å–ø—É–±–ª–∏–∫–∞–Ω—Å–∫–æ–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –ò—Å–ø–∞–Ω–∏–∏"
        """
        sent = sentence.rstrip('.!?')
        sent_lower = sent.lower()
        words = sent.split()

        subject = None
        verb = None
        obj = None

        # –ò—â–µ–º –≥–ª–∞–≥–æ–ª
        verbs = [
            '–ø—Ä–∏–≤–µ–ª', '–ø—Ä–∏–≤–µ–ª–∞', '–ø—Ä–∏–≤–µ–ª–æ', '–ø—Ä–∏–≤–µ–ª–∏',
            '—Å—Ç—Ä–µ–º–∏–ª—Å—è', '—Å—Ç—Ä–µ–º–∏–ª–∞—Å—å', '—Å—Ç—Ä–µ–º–∏–ª–∏—Å—å',
            '–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞', '–ø–æ–¥–¥–µ—Ä–∂', '–ø–æ–º–æ–≥',
            '–Ω–∞—á–∞–ª', '–Ω–∞—á–∞–ª–∞—Å—å', '–Ω–∞—á–∞–ª–æ—Å—å', '–Ω–∞—á–∞–ª–æ—Å—å',
            '–≤—ã–∑–≤–∞–ª', '–≤—ã–∑–≤–∞–ª–∞', '–≤—ã–∑–≤–∞–ª–æ', '–≤—ã–∑–≤–∞–ª–∏',
            '–≤—ã–¥–≤–∏–Ω—É–ª', '–≤—ã–¥–≤–∏–Ω—É–ª–∞',
            '—Å–æ–∑–¥–∞–ª', '—Å–æ–∑–¥–∞–ª–∞', '—Å–æ–∑–¥–∞–ª–æ', '—Å–æ–∑–¥–∞–ª–∏',
            '–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞',
            '—Å—Ç–∞–ª', '—Å—Ç–∞–ª–∞', '—Å—Ç–∞–ª–æ',
            '–ø–æ–∫–∞–∑—ã–≤–∞', '–ø–æ–∫–∞–∑–∞–ª',
            '–∏–≥—Ä–∞–ª', '–∏–≥—Ä–∞–ª–∞', '–∏–≥—Ä–∞–ª–æ',
            '–±–æ—Ä–æ–ª—Å—è', '–±–æ—Ä–æ–ª–∞—Å—å',
            '—É—á–∞—Å—Ç–≤–æ–≤–∞–ª', '—É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∞',
            '–ø—Ä–æ–≤–µ–ª', '–ø—Ä–æ–≤–µ–ª–∞', '–ø—Ä–æ–≤–æ–¥–∏',
            '–ø—Ä–µ–¥–ø—Ä–∏–Ω—è–ª', '–ø—Ä–µ–¥–ø—Ä–∏–Ω—è–ª–∞',
            '—Å–æ–≤–µ—Ä—à–∏–ª', '—Å–æ–≤–µ—Ä—à–∏–ª–∞'
        ]

        verb_idx = -1
        for i, word in enumerate(words):
            w_lower = word.lower()
            if any(v in w_lower for v in verbs):
                verb = word.rstrip('.,;:')
                verb_idx = i
                break

        if verb_idx >= 0:
            # –ü–æ–¥–ª–µ–∂–∞—â–µ–µ - –æ–±—ã—á–Ω–æ –ø–µ—Ä–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–¥ –≥–ª–∞–≥–æ–ª–æ–º
            skip = {'–≤', '–Ω–∞', '–ø–æ', '–∏–∑', '–∫', '–ø—Ä–∏', '–æ—Ç', '–ø–æ–¥', '–Ω–∞–¥', '—Å', '–æ', '–æ–±', '–∏', '–∏–ª–∏', '–Ω–æ'}
            for i in range(verb_idx):
                w = words[i].lower()
                if w not in skip and len(w) > 2:
                    subject = words[i].rstrip('.,;:')
                    break

            # –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ - –≤—Å—ë –ø–æ—Å–ª–µ –≥–ª–∞–≥–æ–ª–∞ –¥–æ —Ç–æ—á–∫–∏
            if verb_idx + 1 < len(words):
                obj_words = []
                for i in range(verb_idx + 1, len(words)):
                    obj_words.append(words[i].rstrip('.,;:'))
                if obj_words:
                    obj = ' '.join(obj_words)

        return subject, verb, obj

    def _generate_question_from_parts(self, subject: str, verb: str, obj: str, sentence: str) -> Optional[str]:
        """
        –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–µ–π
        """
        verb_lower = verb.lower() if verb else ""

        # –ü—Ä–∞–≤–∏–ª–æ 1: –≥–ª–∞–≥–æ–ª "–ø—Ä–∏–≤–µ–ª/–ø—Ä–∏–≤–µ–ª–∞" ‚Üí "–ö —á–µ–º—É –ø—Ä–∏–≤–µ–ª X?"
        if '–ø—Ä–∏–≤–µ–ª' in verb_lower:
            if subject:
                return f"–ö —á–µ–º—É –ø—Ä–∏–≤–µ–ª {subject}?"
            return "–ö —á–µ–º—É —ç—Ç–æ –ø—Ä–∏–≤–µ–ª–æ?"

        # –ü—Ä–∞–≤–∏–ª–æ 2: –≥–ª–∞–≥–æ–ª "—Å—Ç—Ä–µ–º–∏–ª—Å—è" ‚Üí "–ö —á–µ–º—É —Å—Ç—Ä–µ–º–∏–ª—Å—è X?"
        if '—Å—Ç—Ä–µ–º–∏–ª' in verb_lower:
            if subject:
                return f"–ö —á–µ–º—É —Å—Ç—Ä–µ–º–∏–ª—Å—è {subject}?"
            if obj:
                return f"–ö —á–µ–º—É —Å—Ç—Ä–µ–º–∏–ª–∏—Å—å?"
            return "–ö —á–µ–º—É —Å—Ç—Ä–µ–º–∏–ª–∏—Å—å?"

        # –ü—Ä–∞–≤–∏–ª–æ 3: –≥–ª–∞–≥–æ–ª "–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª" ‚Üí "–ö–æ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª X?"
        if '–ø–æ–¥–¥–µ—Ä–∂' in verb_lower or '–ø–æ–º–æ–≥' in verb_lower:
            if subject:
                return f"–ö–æ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª {subject}?"
            return "–ö–æ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª–∏?"

        # –ü—Ä–∞–≤–∏–ª–æ 4: –≥–ª–∞–≥–æ–ª "–≤—ã–∑–≤–∞–ª" ‚Üí "–ß—Ç–æ –≤—ã–∑–≤–∞–ª X?"
        if '–≤—ã–∑–≤–∞' in verb_lower:
            if obj:
                return f"–ß—Ç–æ –≤—ã–∑–≤–∞–ª {subject or '—ç—Ç–æ—Ç'} –∫–æ–Ω—Ñ–ª–∏–∫—Ç?"
            return "–ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ?"

        # –ü—Ä–∞–≤–∏–ª–æ 5: –≥–ª–∞–≥–æ–ª "–≤—ã–¥–≤–∏–Ω—É–ª" ‚Üí "–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤—ã–¥–≤–∏–Ω—É–ª X?"
        if '–≤—ã–¥–≤–∏–Ω—É' in verb_lower:
            if subject:
                return f"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤—ã–¥–≤–∏–Ω—É–ª {subject}?"
            return "–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –±—ã–ª–∏ –≤—ã–¥–≤–∏–Ω—É—Ç—ã?"

        # –ü—Ä–∞–≤–∏–ª–æ 6: –≥–ª–∞–≥–æ–ª "—Å–æ–∑–¥–∞–ª" ‚Üí "–ß—Ç–æ —Å–æ–∑–¥–∞–ª X?"
        if '—Å–æ–∑–¥–∞–ª' in verb_lower or '—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞' in verb_lower:
            if obj:
                return f"–ß—Ç–æ —Å–æ–∑–¥–∞–ª {subject or '–æ–Ω'}?"
            return "–ß—Ç–æ –±—ã–ª–æ —Å–æ–∑–¥–∞–Ω–æ?"

        # –ü—Ä–∞–≤–∏–ª–æ 7: –≥–ª–∞–≥–æ–ª "–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞" ‚Üí "–ß—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª X?"
        if '–¥–µ–º–æ–Ω—Å—Ç—Ä' in verb_lower or '–ø–æ–∫–∞–∑—ã–≤–∞' in verb_lower:
            if subject:
                return f"–ß—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª {subject}?"
            if obj:
                return f"–ß—Ç–æ —ç—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–ª–æ?"
            return "–ß—Ç–æ —ç—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–æ?"

        # –ü—Ä–∞–≤–∏–ª–æ 8: –≥–ª–∞–≥–æ–ª "—Å—Ç–∞–ª" ‚Üí "–ß–µ–º —Å—Ç–∞–ª X?"
        if verb_lower.startswith('—Å—Ç–∞–ª') or verb_lower.startswith('—Å—Ç–∞–ª–∞') or verb_lower.startswith('—Å—Ç–∞–ª–æ'):
            if obj:
                return f"–ß–µ–º —Å—Ç–∞–ª {subject}?"
            return "–ß–µ–º —ç—Ç–æ —Å—Ç–∞–ª–æ?"

        # –ü—Ä–∞–≤–∏–ª–æ 9: –≥–ª–∞–≥–æ–ª "–∏–≥—Ä–∞–ª" ‚Üí "–ö–∞–∫—É—é —Ä–æ–ª—å –∏–≥—Ä–∞–ª X?"
        if '–∏–≥—Ä–∞–ª' in verb_lower:
            if subject:
                return f"–ö–∞–∫—É—é —Ä–æ–ª—å –∏–≥—Ä–∞–ª {subject}?"
            return "–ö–∞–∫—É—é —Ä–æ–ª—å —ç—Ç–æ –∏–≥—Ä–∞–ª–æ?"

        # –ü—Ä–∞–≤–∏–ª–æ 10: –≥–ª–∞–≥–æ–ª "–ø—Ä–æ–≤–µ–ª" ‚Üí "–ß—Ç–æ –ø—Ä–æ–≤–µ–ª X?"
        if '–ø—Ä–æ–≤–µ–ª' in verb_lower or '–ø—Ä–æ–≤–æ–∂–¥–µ' in verb_lower:
            if subject:
                return f"–ß—Ç–æ –ø—Ä–æ–≤–µ–ª {subject}?"
            if obj:
                return f"–ö–∞–∫—É—é –æ–ø–µ—Ä–∞—Ü–∏—é –ø—Ä–æ–≤–µ–ª–∏?"
            return "–ß—Ç–æ –±—ã–ª–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ?"

        # –ü—Ä–∞–≤–∏–ª–æ 11: –≥–ª–∞–≥–æ–ª "—É—á–∞—Å—Ç–≤–æ–≤–∞–ª" ‚Üí "–ì–¥–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª X?"
        if '—É—á–∞—Å—Ç–≤–æ–≤–∞' in verb_lower:
            if subject:
                return f"–ì–¥–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª {subject}?"
            return "–ì–¥–µ —ç—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª–æ?"

        # Fallback
        if subject and obj:
            return f"–ö–∞–∫–æ–≤–∞ –±—ã–ª–∞ —Ä–æ–ª—å {subject} –≤ {obj}?"
        if subject:
            return f"–ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ —Å {subject}?"

        return None

    def generate_qa_pair_from_sentence(self, sentence: str) -> Optional[Dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Q&A –ø–∞—Ä—É –∏–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        try:
            if len(sentence) < 20:
                return None

            # ‚úÖ –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            subject, verb, obj = self._extract_parts(sentence)

            # –ï—Å–ª–∏ –Ω–µ—Ç –≥–ª–∞–≥–æ–ª–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if not verb:
                return None

            # ‚úÖ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å
            question = self._generate_question_from_parts(subject or "", verb, obj or "", sentence)

            if not question:
                return None

            if not question.endswith('?'):
                question += '?'

            if len(question) < 5 or len(question) > 200:
                return None

            if not re.search(r'[–∞-—è–ê-–Ø—ë–Å]', question):
                return None

            answer = sentence.strip()

            if len(answer) < 20:
                return None

            return {
                "question": question,
                "answer": answer,
                "context": sentence[:100]
            }

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}", flush=True)
            return None

    def process_pdf_with_cancellation(self, file_path: str, max_cards: int, db: Session, status_id: int) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF"""
        print(f"\nüîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {file_path}...", flush=True)
        print(f"üéØ –ú–∞–∫—Å–∏–º—É–º: {max_cards} –∫–∞—Ä—Ç–æ—á–µ–∫", flush=True)

        paragraphs = self.extract_meaningful_text(file_path)

        if not paragraphs:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞–±–∑–∞—Ü–µ–≤!", flush=True)
            return []

        flashcards = []
        seen_questions = set()

        for p_idx, para_dict in enumerate(paragraphs):
            if len(flashcards) >= max_cards:
                break

            para_text = para_dict["text"]
            sentences = self._split_into_sentences(para_text)

            print(f"\nüìñ –ê–±–∑–∞—Ü {p_idx + 1}: {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

            for sentence in sentences:
                if len(flashcards) >= max_cards:
                    break

                if db is not None:
                    try:
                        status = db.query(models.ProcessingStatus).filter(
                            models.ProcessingStatus.id == status_id
                        ).first()

                        if status and status.should_cancel:
                            print(f"‚õî –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞", flush=True)
                            return flashcards[:max_cards]
                    except:
                        pass

                qa_pair = self.generate_qa_pair_from_sentence(sentence)

                if qa_pair:
                    question = qa_pair["question"]

                    if question not in seen_questions:
                        seen_questions.add(question)
                        flashcards.append({
                            "question": question,
                            "answer": qa_pair["answer"],
                            "context": qa_pair["context"],
                            "source": ""
                        })
                        print(f"  ‚úÖ [{len(flashcards)}/{max_cards}] {question}", flush=True)

                        if len(flashcards) >= max_cards:
                            break

        print(f"\n‚úÖ –ò—Ç–æ–≥–æ: {len(flashcards)} –∫–∞—Ä—Ç–æ—á–µ–∫ (–ª–∏–º–∏—Ç: {max_cards})", flush=True)
        return flashcards[:max_cards]

    def process_pdf(self, file_path: str, max_cards: int = 10) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF"""
        return self.process_pdf_with_cancellation(file_path, max_cards, None, None)